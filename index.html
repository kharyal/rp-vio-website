<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	.AuthorsTitle{
		margin-top: 30px;
		margin-left: auto;
		margin-right: auto;
		margin-bottom: 2px;
		font-family: 'Fanwood Text';
		font-weight:'400';
		font-size: 30;
		font-weight: bold;
	}
	.pageTitle{
		margin-top: 20px;
		font-family: 'Times New Roman', serif;
		font-size: 35;
		max-width: 800px;
		text-align: center;
		margin-left: auto;
		margin-right: auto;
	}
	.Authors{
		margin-top: 0px;
		margin-left: auto;
		font-family: 'Fanwood Text';
		font-weight:'400';
		font-size: 20;
	}
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	figcaption{
		width:600px; 
		margin-top:0.2cm; 
		text-align: justify;
		font-size:15px
	}
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>RP-VIO</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Creative and Descriptive Paper Title." />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span class=pageTitle style="font-size:36px">RP-VIO: Robust Plane-based Visual-Inertial <br> Odometry for Dynamic Environments</span>
		<table align=center width=900px>
			<table align=center width=900px style="margin-top:0.5cm;margin-bottom:0.2cm" class="Authors">
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://karnikram.info/">Karnik Ram</a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="https://kharyal.github.io/">Chaitanya Kharyal</a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="https://github.com/sudarshan-s-harithas">Sudarshan Harithas</a></span>
						</center>
					</td>
					<td align=center width=150px>
						<center>
							<span style="font-size:24px"><a href="https://faculty.iiit.ac.in/~mkrishna/">Madhava Krishna</a></span>
						</center>
					</td>
				</tr>
			</table>
			<a href="https://en.wikipedia.org/wiki/James_J._Gibson" style="font-size:20px; margin-top:0.5cm;">IIIT Hyderabad</a></span>
			
			<table align=center width=900px style="margin-top:0.2cm;">
				<tr>
					<td align=center>
						<span style="font-size:20px">International Conference on Intelligent Robots and Systems (IROS) 2021</span><br>
					</td>
				</tr>
			</table>
			
			<table align=center width=600px style="margin-top:0.7cm;">
				<tr>
					<td align=center width=600px>
						<center>
							<span style="font-size:20px"><a href='https://arxiv.org/abs/2103.10400'>[Paper]</a>
								<a href='https://github.com/karnikram/rp-vio'>[Code]</a>
								<a href='https://www.youtube.com/watch?v=Fp4l8JkuD30'>[Presentation Video]</a></span>
						</center>
					</td>
					<!-- <td align=center width=120px>
						<center>
							<span style="font-size:20px"><a href='https://github.com/karnikram/rp-vio'>[Code on GitHub]</a></span><br>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:20px"><a href='https://www.youtube.com/watch?v=Fp4l8JkuD30'>[Presentation Video]</a></span>
						</center>
					</td> -->
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=1000px>
			<tr>
				<td width=1000px>
					<center>
						<img class="round" style="width:1000px" src="./resources/teaser.png"/>
					</center>
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px style="text-align: justify">
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Modern visual-inertial navigation systems (VINS) are faced with a critical challenge in real-world deployment: they need to operate reliably and robustly in highly dynamic environments. Current best solutions merely filter dynamic objects as outliers based on the semantics of the object category. Such an approach does not scale as it requires semantic classifiers to encompass all possibly-moving object classes; this is hard to define, let alone deploy. On the other hand, many real-world environments exhibit strong structural regularities in the form of planes such as walls and ground surfaces, which are also crucially static. We present RP-VIO, a monocular visual-inertial odometry system that leverages the simple geometry of these planes for improved robustness and accuracy in challenging dynamic environments. Since existing datasets have a limited number of dynamic elements, we also present a highly-dynamic, photorealistic synthetic dataset for a more effective evaluation of the capabilities of modern VINS systems. We evaluate our approach on this dataset, and three diverse sequences from standard datasets including two real-world dynamic sequences and show a significant improvement in robustness and accuracy over a state-of-the-art monocular visual-inertial odometry system. We also show in simulation an improvement over a simple dynamic-features masking approach. Our code and dataset are publicly available.
			</td>
		</tr>
		<tr><td></td></tr><tr><td></td></tr><tr><td></td></tr><tr><td></td></tr>
		<tr>
			<td>
				<center><h1>Method</h1></center>
			</td>
		</tr>
		<tr>
			<td>
				<center>
					Method Here!
				</center>
			</td>
		</tr>
		<tr>
			<td>
				<center>
					<figure>
						<img class="round" style="width:350px" src='./resources/overview.png'/>
						<figcaption> Figure 1. <b>Overview:</b> Motivated by the presence of large planar surfaces in man-made environments, we propose a monocular VIO system that estimates motion only from one or more planes in the scene based on their induced homographies, and ignoring all off-the-plane features. We show that this leads to improved robustness and accuracy in dynamic environments. blue path indicates the estimated trajectory and magenta path indicates the ground truth.</figcaption>
					</figure>
				</center>
			</td>
		</tr>
		<tr>
			<td>
				<center>
					<figure>
						<img class="round" style="width:900px" src='./resources/plane.png'/>
						<figcaption> Figure 2. <b>Plane Segmentation:</b> Segmentation outputs for two challenging images in the OpenLORIS sequence, from the original model and the model modified
							with our inter-plane loss are visualized. The output from our model is further refined with a dense-CRF, before being used by our VIO
							system, and is also visualized here.
							</figcaption>
					</figure>
				</center>
			</td>
		</tr>
		<tr>
			<td>
				<center>
					<figure>
						<img class="round" style="width:900px" src='./resources/results.png'/>
						<figcaption> Figure 3. <b>Result:</b> Top-view comparison between RP-VIO-Single (blue),
							VINS-Mono (green), and ground truth (magenta), on the
							OpenLORIS market-1 sequence.
							
							</figcaption>
					</figure>
				</center>
			</td>
		</tr>
	</table>
	<br>

	<hr>
	<center><h1>Talk</h1></center>
	<p align="center">
		<iframe width="560" height="315" src="https://www.youtube.com/embed/Fp4l8JkuD30" frameborder="0" allowfullscreen></iframe>
	</p>

	<table align=center width=800px>
		<br>
		<tr>
			<center>
				<span style="font-size:28px"><a href=''>[Slides]</a>
				</span>
			</center>
		</tr>
	</table>
	<hr>

	<center><h1>Code</h1></center>

	<table align=center width=420px>
		<center>
			<tr>
				<td>
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px>
				<center>
					<td><img class="round" style="width:450px" src="./resources/method_diagram.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					Short description if wanted
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=800px>
		<br>
		<tr><center>
			<span style="font-size:28px">&nbsp;<a href='https://github.com/richzhang/webpage-template'>[GitHub]</a>
			</center>
		</span>
	</table>
	<br>
	<hr>
	<table align=center width=550px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">Karnik Ram, Chaitanya Kharyal, Sudarshan S. Harithas, K. Madhava Krishna<br>
				<b>RP-VIO: Robust Plane-based Visual-Inertial Odometry for Dynamic Environments</b><br>
				IROS, 2021.<br>
				(hosted on <a href="https://arxiv.org/abs/2103.10400">ArXiv</a>)<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

